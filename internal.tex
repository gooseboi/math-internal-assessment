\documentclass{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{float}
\usepackage{helvet}
\usepackage{import}
\usepackage{lmodern}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{setspace}
\usepackage{titling}
\usepackage{url}
\usepackage{fontspec}
\usepackage[section]{placeins}
\pgfplotsset{compat = newest}
\usepackage[skip=10pt plus1pt, indent=40pt]{parskip}

\setmainfont{Arial}
\setsansfont{Arial}
\setmonofont{Arial}

\def\graphscale{0.85}

\usepackage[backend=biber,style=apa]{biblatex}
\addbibresource{bibliography.bib}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=blue,
}

\allowdisplaybreaks

\author{Guzm√°n Zugnoni}
\title{Non-integer order derivatives}

\renewcommand{\maketitle}{
\begin{center}
	\Huge\textbf \thetitle
\end{center}
}

\setlength{\parindent}{0pt}
%\setlength{\parskip}{20pt}
\doublespacing
\renewcommand{\familydefault}{\sfdefault}

\def\squad{\hskip2\fontdimen3\font}

\DeclareMathOperator{\di}{\,d\!}
\newcommand*\Eval[3]{\left[#1\right]_{#2}^{#3}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\IntSub}[1]{
{\textup{Substitution:}} \\
&\quad
\boxed{\begin{aligned}
		#1
\end{aligned}}
}

\begin{document}
\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

My interest in this topic was born when we learned about the notion of second
and higher order derivatives. We learnt that there was a meaning and an
application of taking a derivative multiple times. However, when learning about
second order derivatives, the notation used to represent this operation made
me relate it to another concept we had learnt about, exponents.

To represent the second derivative for instance, one writes $\frac{d^2}{dx^2}$,
which encodes the fact that $\frac{d}{dx}$ was written twice by ``multiplying''
them and writing a $2$ in the exponent. This made me think about
exponentiation, which is the process of repeated multiplication, where
similarly $x \cdot x = x^2$. However, for exponentiation, we learn that it is
possible to exponentiate to non-integral, and non-positive powers, such as
$x^{-1}=\frac{1}{x}$ or $x^\frac{1}{2} = \sqrt{x}$, which have meaning and are
useful in solving mathematical problems, and this led me to think about if
there existed a similar notion regarding derivatives.

My aim in this exploration is going to be to find a way to generalise
higher-order derivatives to all $\mathbb{R}$, and not only
$\mathbb{Z}_{\geq0}$, and to study the properties that this generalisation may
present.

\section{Negative order derivatives} \label{neg_order_ders}

The most natural order to start defining non-integral derivatives is the same
order in which non-integer exponents are first learned: exponentiating to
negative integers. The expression $\frac{d^{-1}}{dx^{-1}}$ has no obvious
meaning, but it can be interpreted like one interprets exponents

Firstly, throughout the exploration, I will use the notation
$$  \frac{d^\alpha}{dx^\alpha}=\
	D^\alpha \quad \forall \squad \alpha \in \mathbb{R}$$
And for an arbitrary $\alpha$-differentiable function $f$:
$$\frac{d^\alpha}{dx^\alpha}\left(f\right) = D^\alpha f$$

Now using this notation, by the definition of the second derivative, given an
arbitrary differentiable function $f$: $$D^1D^1 f = D^2 f$$ This can also be
extended for the notion of a third derivative: $$D^1D^2 f = D^3 f$$ It can be
extrapolated that, more generally,
\begin{equation}
	\label{der_sum}
	D^nD^m = D^{n+m} \quad \forall \squad n,m \in \mathbb{Z}^{+}
\end{equation}

This leads to defining negative order derivatives like negative order
exponents, where $x^1 \cdot x^{-1}= x^0$. Similarly, one might say that, by
(\ref{der_sum})
\begin{equation}
	\label{inv_eq}
	D^1D^{-1} f = D^0 f
\end{equation}
and this leads to having to define what $D^0$ means.

It makes sense intuitively that taking the derivative of a function 0 times
would leave it without change, but I will check this verifies
algebraically. This is easy to do, as $$D^1 D^0 f = D^{1+0} f = D^1 f$$
Removing the $D^1$ from both sides by taking their integrals gives the equation
$$D^0 f = f$$ which proves the intuition that this operation does nothing. This
means that the 0th power of the derivative operator is the identity operator.

Going back to (\ref{inv_eq}), we now see that
\begin{equation}
	\label{inv_eq_simplified}
	D^1D^{-1} f = f
\end{equation}
Since this is true for any arbitrary differentiable function $f$, and the order
of these two doesn't matter, i.e. $D^1D^{-1}=D^{-1}D^1$, we see these two
operators are inverses of each other, as composing them results in the
identity. Luckily, we know the inverse to the derivative operator, and that is
the integral. To find the value of $D^{-1}$, we can take the integral of both
sides of (\ref{inv_eq_simplified}), leading to
$$
D^{-1} f = \int f dx
$$

Which, when applying $D^{-1}$ n times, leads to the result
$$
D^{-n} f = \underbrace{\int \int \ldots \int}_\text{$n$ times}
		   f\left(t\right) \di t \qquad \forall n \in \mathbb{Z}
$$

So far, negative order derivatives seem simple, as they match an initial
intuition very cleanly: 0th derivatives do nothing, and negative derivatives do
the opposite to a derivative. While this matches the intuition, this might have
been wrong, and it is important to verify this formally

After learning about negative derivatives, one may see that they are hard to
evaluate, as a consequence of them involving integrals.

For instance, taking $f = \frac{8}{(x^2+1)^3}$:
$$
D^2\left(\frac{8}{(x^2+1)^3}\right) =
D\left(\frac{-48x}{(x^2+1)^4}\right) =
\frac{48x(7x^2-1)}{(x^2+1)^5}
$$

Despite there not being a general formula for the nth derivative of an
arbitrary function, one can easily arrive at the desired derivative by
performing repeated derivatives.

However, when trying to do the opposite, i.e. $D^{-2}$, the process is much
harder:

$$
D^{-2}\left(\frac{8}{(x^2+1)^3}\right) =
D^{-1}\left(\frac{x\left(3x^2+5\right)}{\left(x^2+1\right)^2} +
3\tan^{-1}{x} + C_1 \right)
$$

And performing the process of integration again will result in an even more
complicated result, with which performing repeated integration becomes
increasingly harder every time. Therefore, there is motivation to find a
suitable alternative to performing the integral every time, and a method to do
this is known as Cauchy's formula for repeated integration.

\section{Cauchy's formula for repeated integration}

The motivation for this formula is finding areas of threedimensional objects,
where integration may be performed twice to find the volume of an
object. However this formula may be used for the purposes of this investigation.

Cauchy's formula for repeated intregration is given thusly:
$$
\int_a^x
\int_a^{t_1}
\int_a^{t_2}
\ldots
\int_a^{t_{n-1}}f\left(t_n\right) dt_n \ldots dt_2 dt_1
=
\frac{1}{(n-1)!}\int_a^x\left(x-t\right)^{n-1}f\left(t\right)dt.
$$
where here $a$ is an arbitrary constant, alike the constant of integration.

This formula may be used to calculate the nth antiderivative for any function
performing a single integration. I will give a few examples of this method in
use, calculating them both by the normal method and Cauchy's Formula. For the
sake of ease, I will assume appropiate initial conditions such that all
constant of integration will be $0$.


\subsection{Proof for \texorpdfstring{$n \in \mathbb{Z}$}{n in Z}}

This may be proven for $n \in \mathbb{Z}^+$ by induction, for an arbitrary
integrable function $f$. The base case is n=1, where it should simply be equal
to
$\int
f\left(x\right)dx$:
$$
\frac{1}{(1-1)!}\int_a^x\left(x-t\right)^{1-1}f\left(t\right)dt =
\frac{1}{(0)!}\int_a^x\left(x-t\right)^{0}f\left(t\right)dt =
\int_a^xf\left(t\right)dt
$$
The last integral is the same as the indefinite integral, as it evaluates to
the antiderivative at $x$, $F(x)$, plus a constant $C$, which in this case is
$-f(a)$, which means that the base case is true.

Thus, let $P_n$ be the proposition that Cauchy's formula holds for $n$. We may
assume that $P_k$ holds for some $k \in \mathbb{Z}^+$, and prove $P_{k+1}$
holds.

The formula for $n = k + 1$ would be:
$$
\int_a^x
\boxed{
\int_a^{t_1}
\int_a^{t_2}
\ldots
\int_a^{t_{k-1}}
\int_a^{t_k}f\left(t_{k+1}\right) \di t_{k+1}\di t_k\di t_{k-1} \ldots \di t_2}\di t_1
$$
The boxed region contains $k$ integrals, and thus, since $P_k$ holds, we may apply
Cauchy's formula to the integrals, which would result in the expression:
$$
\int_a^x
\frac{1}{(k-1)!}\int_a^{t_1}\left(t_1-t\right)^{k-1}f\left(t\right)\di t\di t_1
$$

Since when substituting $k+1$ in the formula the $x-t$ expression is raised to
the $k$th power, it is a good idea to achieve this. To do this, we must raise
the current power by 1, which may be achievable by writing it as a derivative,
like so:
$$
\int_a^x
\frac{1}{(k-1)!}\int_a^{t_1}\frac{\di}{\di t_1}\left[\frac{1}{n}\left(t_1-t\right)^k f\left(t\right)\right]\di t\di t_1
$$
The $f(t)$ term is included in the derivative, as it is a constant in terms of
$t_1$. This expression is very similar to the Fundamental Theorem of Calculus,
which states:
$$
\frac{\di}{\di x}\int_a^bf(x)\di x = \int_a^b\frac{\di}{\di x}f(x) \di x = f(b)- f(a)
$$

Applying the Fundamental Theorem of Calculus results in the expression becoming
\begin{gather*}
\int_a^x
\frac{1}{(k-1)!}\frac{\di}{\di t_1}\left[\int_a^{t_1}\frac{1}{n}\left(t_1-t\right)^k f(t)\di t\right]\di t_1 \\
\int_a^x
\frac{\di}{\di t_1}\left[\frac{1}{(k-1)!}\int_a^{t_1}\frac{1}{n}\left(t_1-t\right)^k f(t)\di t\right]\di t_1 \\
\int_a^x
\frac{\di}{\di t_1}\left[\frac{1}{(k-1)!}\frac{1}{n}\int_a^{t_1}\left(t_1-t\right)^k f(t)\di t\right]\di t_1 \\
\int_a^x
\frac{\di}{\di t_1}\left[\frac{1}{k!}\int_a^{t_1}\left(t_1-t\right)^k f(t)\di t\right]\di t_1
\end{gather*}
Applying the Fundamental Theorem of Calculus again eliminates the outer integral,
and results in
$$
\frac{1}{k!}\int_a^x\left(x-t\right)^k f(t)\di t -
\frac{1}{k!}\int_a^a\left(a-t\right)^k f(t)\di t =
\frac{1}{k!}\int_a^x\left(t_1-t\right)^k f(t)\di t
$$
which is $P_{k+1}$, and therefore by the principle of mathematical induction,
$$
\left(\left(P_k \implies P_{k+1}\right) \land P_1\right)
\implies P_n \forall n \in \mathbb{Z}^+
\qquad \blacksquare
$$

\subsection{Example}
As an example of how to use this formula, I will calculate a simple antiderivative,
that of $x^2$. Firstly, using the simple method of integration.
\begin{flalign*}
	\iiiint x^2 \di x\di x\di x\di x
	&=\iiint \frac{x^3}{3} \di x\di x\di x \\
	&=\iint \frac{x^4}{12}\di x\di x \\
	&=\int \frac{x^5}{60} \di x \\
	&=\frac{x^6}{360}
\end{flalign*}
And secondly, using Cauchy's formula for integration:
\begin{flalign*}
	\frac{1}{(4-1)!}\int_0^x \left(x-t\right)^{4-1}	t^2 \di t
	=&\frac{1}{3!}\int_0^x \left(x-t\right)^3 t^2 \di t\\
	=&\frac{1}{6}\int_0^x \left(x^3 - 3x^2t + 3xt^2 - t^3\right)t^2 \di t \\
	=&\frac{1}{6}\int_0^x x^3t^2 - 3x^2t^3 + 3xt^4 - t^5 \di t \\
	=&\frac{1}{6} \Eval{\frac{x^3t^3}{3} - \frac{3x^2t^4}{4} + \frac{3xt^5}{5} - \frac{t^6}{6}}{0}{x} \\
	=&\frac{1}{6} \left(\frac{1}{3}x^6 - \frac{3}{4} x^6 + \frac{3}{5} x^6 - \frac{1}{6}x^6 \right) \\
	=&\frac{1}{6} \left(\frac{x^6}{60} \right) \\
	=&\frac{x^6}{360}
\end{flalign*}

The results are the same and thus the formula seems to hold for a simple
function. However, one may realise that the second solution is in fact longer
and more complex than the traditional way of evaluating the integral. This is
much more evident, for instance in the example of $D^{-3} \sin{x}$, where
$\iiint \sin{x} \di x$ is rather easy to evaluate because of the simplicity and
cyclical nature of its antiderivatives, whereas $\frac{1}{2}\int
\left(x-t\right)^2 \sin t\di t$ involves much more work and complex
techniques. This is a result of the fact that integrals tend to become more
complex to evaluate when more terms are introduced. Thus, despite the fact that
this compresseses the work needed to be done to one integral, the complexity is
much greater.

This means that Cauchy's formula is in fact, not a practical way to calculate
negative order derivatives in most situations, even though it seems like it
would be. Cauchy's formula, however, can be applied in other areas of
mathematics, like applied mathematics for calculating integrals numerically in
multi-variable calculus for instance, which are outside the scope of this
exploration. In addition, Cauchy's formula has one particular use that this exploration
is interested in, and that is the ability to use it to extend repeated integration
to non-integer iterations.

\subsection{Generalising Cauchy's integral formula for \texorpdfstring{$x \in \mathbb{R}$}{x in R}}

Now that a generalisation of performing the inverse of a derivative a number of
times has been established, it is reasonable to assume that this might make it
possible to extend this operation to all reals.

This is true, as it is possible, however, a slight consideration must be made.
The formula for repeated integration is thus

$$
D^{-n}f(x) = \frac{1}{(n-1)!}\int_a^{x}\left(x-t\right)^{n-1}f(t)\di t
$$

However, if one tries to substitute something that is not a positive integer
for n, one comes across the problem of having to evaluate
$\frac{1}{(n-1)!}$. Generalising factorials to all $\mathbb{R}$ is complex,
involving techniques in real analysis. However, since this is not the focus of
this exploration, I will use the result without proving it. This generalisation
is named $\Gamma(x)$, and its formula is given as
$$
\Gamma(x)=\int_0^{\infty} e^{-t}t^{x-1}dt = (x-1)!
$$
Having this function, we can thus express the formula for repeated integration as
$$
D^{-\alpha}f(x) = \frac{1}{\Gamma\left(\alpha\right)}\int_a^{x}\left(x-t\right)^{\alpha-1} f(t)\di t
$$

Before continuining, it is important to clarify how this helps the goal of this
exploration, as the exploration intended to find a way to take fractional
derivatives, and we have only found a way to take fractional integrals.

However, a way to find fractional derivatives from integrals is very easy to
define. For instance, if we want to find $D^\frac{1}{2}$, we may re-write this
as $D^1D^{-\frac{1}{2}}$, by the properties discussed in section
\ref{neg_order_ders}, as $\frac{1}{2}=1+\left(-\frac{1}{2}\right)$. Moreover,
we know how to calculate both operators in the second equation, as $D^1$ is
just the first derivative, and $D^{-\frac{1}{2}}$ can be calculated with the
method discussed in this section.

Having said this, we can now define fractional calculus and its main operator,
the differintegral.


\section{Fractional calculus}
\subsection{The differintegral operator}
Having defined a way to take integrals a non-integral number of times, we can
now define an operator that can ``take the derivative $x$ times'', where
$x$ could be any real number

One way to approach this is that, to take $D^2$ for instance, we may take
$D^{-\left(-2\right)}$ and evaluate using Cauchy's formula. However, this does
not work, as when trying to evaluate $\Gamma(-1)$ when substituting into the
formula, we find that it is not defined. In addition, $\Gamma$ is not defined
for any negative integer and thus we must define an operator that can take
these derivatives another way.

To do this, it is useful to split all numbers into their integer and
non-integral parts. To start with, we consider a positive number $x \in
\mathbb{R}^+$, which we split into its integer and its fractional part: $x = n +
\alpha, \quad n \in \mathbb{Z}^+, \squad 0 \leq \alpha < 1$, which is the
decomposition of the number as its integer and real part. Therefore, we could
write $D^x=D^nD^\alpha$, by the property discussed in the previous
section. This is very useul because $D^n$ is simply the nth derivative, which
is simply defined as the repetition of derivatives, and additionally $D^\alpha$
can be calculated using Cauchy's formula, and therefore we reach the result:

\begin{align*}
	D^x f   &= \frac{d^n}{dx^n} D^\alpha f \\
			&= \frac{d^n}{dx^n} \frac{1}{\Gamma\left(\alpha\right)}
			 \int_a^x (x-t)^{\alpha-1} f(t) \di t
\end{align*}

This same working may also be used for negative numbers: $x = n + \alpha \quad
\alpha,n < 0$, using either Cauchy's Formula or a manual method to compute the
integral $n$ times.

\begin{align*}
	D^x f   &= D^{-n} D^\alpha f \\
			&= \frac{1}{(n-1)!} \int_a^x (x-t)^{n-1}
			 \left(\frac{1}{\Gamma\left(\alpha\right)}
			 \int_0^t (t-\omega)^{\alpha - 1} f(\omega) \di \omega\right)\di t
\end{align*}

This may be condensed into a single operator, for both negative and positive
numbers:
\begin{equation*}
	D^\alpha f(x) =
	\begin{cases}
		\frac{d^n}{dx^n} D^{\alpha - n} f(x)
		& \text{if } \alpha \geq 1, \text{where } n = \floor{\alpha}\\

		I^{-n}D^{\alpha - n} f(x)
		& \text{if } \alpha \leq -1, \text{where } n = \ceil{\alpha} \\

		\frac{d}{dt} \frac{1}{\Gamma\left(\alpha\right)} \int_a^x (x-t)^{\alpha-1} f(t) \di t
		& \text{if } 0 < \alpha < 1 \\

		\frac{1}{\Gamma\left(\alpha\right)} \int_a^x (x-t)^{\alpha-1} f(t) \di t
		& \text{if } -1 < \alpha < 0 \\

		f(x) & \text{if } \alpha = 0
	\end{cases}
\end{equation*}

Where $I^n$ represents the $n$-th integral, which as discussed previously may
be calculated using several methods, like Cauchy's method or manually.

The above method of defining fractional integrals is equivalent to the original
formulation of a ``fractional antiderivative'', which is known as the
Riemann-Liouville integral. This original formulation was proposed by Joseph
Liouville, and it was also named after Bernard Riemann for his contributions to
the study of integrals. \parencite{lizorkin2020}

For instance,
$$
D^{\frac{11}{4}} f = D^{2+\frac{3}{4}}
				 = \frac{d^2}{dx^2}\frac{1}{\Gamma\left(\frac{3}{4}\right)}
				 \frac{d}{dx} \int_a^x\left(x-t\right)^{-\frac{1}{4}} f(t) \di t
$$

and

$$
D^{-\frac{13}{3}} f = D^{-4-\frac{1}{3}}
					= I^4 \frac{1}{\Gamma\left(-\frac{1}{3}\right)} \int_a^x \left(x-t\right)^{-\frac{4}{3}} f(t) \di t
$$

This provides an easy and algorithmic way to calculate the $\alpha$ derivative
of a function, leaving only the inner integral to calculate, which depends on
the function. In the following section, some example derivatives will be
calculated.

However, it is important to note that the fractional derivatives depend on the
variable $a$, which is a constant when taking the integral. This constant is
akin to the constant of integration which is gained when performing normal
integration, introducing an infinite number of possible fractional derivatives.
However, because of the structure of the integral, this constant does not behave
exactly like the normal constant of integration. This will be explored further in subsection \ref{nonlocality}

\subsection{Calculation examples}

To begin with, I will calculate the most simple fraction for the derivative
power, the $\frac{1}{2}$ power, as this is ``the first'' fraction, as it is the
first fraction of the form $\frac{1}{n}$ that is not an integer, and the
function $x^2$, as integer derivatives of polynomials are simple.

$$
D^{\frac{1}{2}} \left(x^n\right) = \frac{d}{dx} \frac{1}{\Gamma\left(\frac{1}{2}\right)} \int_a^x \left(x-t\right)^{-\frac{1}{2}} t^2 \di t
$$

For this purpose, $\Gamma\left(-\frac{1}{2}\right)$ needs to be known, and this
value is a special value of the gamma function, whose calculation is outside
out of the scope of this investigation, but nevertheless gives
$\Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}$.

\begin{flalign*}
	&\frac{d}{dx} \frac{1}{\sqrt{\pi}} \int_a^x \frac{t^2}{\left(x-t\right)^{\frac{1}{2}}} \di t \\
	&\IntSub{
		\text{let } u&=x-t \\
			du&=-dt \\
			t \to a &\implies u \to x-a \\
			t \to x &\implies u \to 0
	} \\
	&=\frac{d}{dx}\frac{-1}{\sqrt{\pi}} \int_{x-a}^0 \frac{\left(x-u\right)^2}{u^{\frac{1}{2}}} \di u && \\
	&= \frac{d}{dx}\frac{-1}{\sqrt{\pi}} \int_{x-a}^0 \frac{x^2-2xu+u^2}{u^{\frac{1}{2}}} \di u && \\
	&= \frac{d}{dx}\frac{1}{\sqrt{\pi}} \int_0^{x-a} x^2u^{-\frac{1}{2}}-2xu^{\frac{1}{2}}+u^{\frac{3}{2}} \di u && \\
	&= \frac{d}{dx}\frac{1}{\sqrt{\pi}} \Eval{2x^2u^{\frac{1}{2}}-\frac{4}{3}xu^{\frac{3}{2}}+\frac{2}{5}u^{\frac{5}{2}}}{u=0}{u=x-a} && \\
	&= \frac{d}{dx}\frac{1}{\sqrt{\pi}} \left(2x^2\left(x-a\right)^{\frac{1}{2}}-\frac{4}{3}x\left(x-a\right)^{\frac{3}{2}}+\frac{2}{5}\left(x-a\right)^{\frac{5}{2}}\right) && \\
	&= \frac{1}{\sqrt{\pi}} \left(4x\left(x-a\right)^{\frac{1}{2}} +
								  \frac{x^2}{\left(x-a\right)^{\frac{1}{2}}} -
								  \frac{4}{3}\left(x-a\right)^{\frac{3}{2}} -
								  2x\left(x-a\right)^{\frac{1}{2}} +
\left(x-a\right)^{\frac{3}{2}}\right) && \\
\end{flalign*}

This answer, in contrast to the usual derivative of $x^2$, this answer is
complex, and involves the constant $\frac{1}{\sqrt{\pi}}$. However, one of the
reasons for this complexity is the generic parameter $a$, which represents a
``starting point'' for the integration. Assigning it the value $a=0$ yields the following, much
simpler answer
\begin{align*}
	&\frac{1}{\sqrt{\pi}} \Eval{\left(4x\left(x-a\right)^\frac{1}{2} +
							   \frac{x^2}{\left(x-a\right)^\frac{1}{2}} -
							   \frac{4}{3}\left(x-a\right)^\frac{3}{2} -
							   2x\left(x-a\right)^\frac{1}{2} +
						       \left(x-a\right)^\frac{3}{2}\right)}
							   {a=0}{}\\
	&=\frac{1}{\sqrt{\pi}} \left(4x\cdot\left(x\right)^\frac{1}{2} +
							   \frac{x^2}{x^\frac{1}{2}} -
							   \frac{4}{3}x^\frac{3}{2} -
							   2x \cdot x^\frac{1}{2} +
						       x^\frac{3}{2}\right) \\
	&=\frac{1}{\sqrt{\pi}} \left(4x^\frac{3}{2} +
								 x^\frac{3}{2}-
							     \frac{4}{3}x^{\frac{3}{2}} -
								 2x^\frac{3}{2} +
						         x^\frac{3}{2}\right) \\
	&=\frac{8}{3\sqrt{\pi}} x^\frac{3}{2}
\end{align*}

Therefore, this is one of the possible half derivatives of $x^2$, as it
corresponds to one possible value of $a$. Moreover, because of the derivative rules
discussed above, it should be true that $D^\frac{1}{2}\frac{8}{3\sqrt{\pi}} x^\frac{3}{2} = 2x$,
as $D^\frac{1}{2}D^\frac{1}{2}x^2=D^{\frac{1}{2} + \frac{1}{2}} x^2=D x^2 = 2x$

Therefore, using the same method as above, we calculate the next half derivative.
\begin{align*}
	&D^\frac{1}{2} \frac{8}{3\sqrt{\pi}} x^\frac{3}{2} \\
	=&\frac{d}{dx}\frac{1}{\sqrt{\pi}} \frac{8}{3\sqrt{\pi}} \int_0^x \left(x-t\right)^{-\frac{1}{2}} t^\frac{3}{2} \di t \\
	=&\frac{d}{dx}\frac{8}{3\pi} \int_0^x \frac{t^\frac{3}{2}}{\left(x-t\right)^\frac{1}{2}} \di t \\
	 &\IntSub{
		 \text{let } u &= \sqrt{t} \\
		\di u &= \frac{1}{2\sqrt{t}} \di t = \frac{1}{2u} \di t \\
		2u \di u &= \di t \\
		t \to 0 &\implies u \to 0 \\
		t \to x &\implies u \to x
	} \\
	=&\frac{d}{dx}\frac{8}{3\pi} \int_0^{\sqrt{x}} \frac{u^3 \cdot 2u}{\sqrt{x-u^2}} \di u \\
	=&\frac{d}{dx}\frac{16}{3\pi} \int_0^{\sqrt{x}} \frac{u^4}{\sqrt{x-u^2}} \di u \\
\end{align*}

Because of the square root in the denominator, with a $x-u^2$, we should use a trigonometric
substitution to solve this, as such:
\begin{align*}
	 &\IntSub{
		 \text{let } u &= \sqrt{x}\sin{w} \\
		 \di u &= \sqrt{x}\cos{w} \di w \\
		 u \to 0 &\implies w \to 0 \\
		 u \to \sqrt{x} &\implies w \to \frac{\pi}{2} \\
	 } \\
	=&\frac{d}{dx}\frac{16}{3\pi} \int_0^{\frac{\pi}{2}} \frac{x^2\sin^4w\cdot \sqrt{x}\cos{w}}{\sqrt{x\left(1-\sin^2w\right)}} \di w \\
	=&\frac{d}{dx}\frac{16}{3\pi} \int_0^{\frac{\pi}{2}} \frac{x^2\sin^4w\cdot \sqrt{x}\cos{w}}{\sqrt{x}\cos w} \di w \\
	=&\frac{d}{dx}\frac{16x^2}{3\pi} \int_0^{\frac{\pi}{2}} \sin^4w \di w \\
	=&\frac{32x}{3\pi} \int_0^{\frac{\pi}{2}} \sin^4w \di w \\
\end{align*}

Because of how the integral is independent of the value of $x$, we can take the
$x$ term out, and evaluate the integral on its own. The value of this integral
is calculable using some substitutions, but the calculation of this integral is
outside of the scope of this investigation. Therefore, the value of this
integral will be taken as a given and not proven. The value of this integral is
$\frac{3\pi}{16}$, and therefore we may calculate the previous derivative.

\begin{align*}
	&\frac{32x}{3\pi} \int_0^{\frac{\pi}{2}} \sin^4w \di w \\
	=&\frac{32x}{3\pi} \frac{3\pi}{16} \\
	=&\frac{32x\cdot3\pi}{16\cdot 3\pi} \\
	=&2x
\end{align*}

The result is what is expected, as applying the half derivative twice resulted
in the same output as the original derivative. However, the general proof of
this is outside the scope of this exploration.

Moreover, it may be observed that the procedure is similar to when using
Cauchy's formula, as performing the procedure to reach the result becomes
increasingly more complex with each term added. Albeit not the same, this is
similar to our introduction to derivatives in class, as it may be easy to find
the derivative of $x^2$ using first principles, but when introducing more
functions, like when taking the derivative of $\sin{\left(x^2+3\right)}$, it
may be harder to do this using first principles, and we use properties of the
derivative like the chain rule and product rule to evaluate more complex
derivatives. Therefore, we are motivated to find if the same properties apply
for fractional derivatives, and if there exist any others unique to them, to
make evaluation easier.


\subsection{Properties of fractional derivatives}

Firstly, fractional derivatives behave rather differently from normal
derivatives, despite composing together to form normal derivatives, for
instance, when taking $D^\frac{1}{2}$ of $f(x)=c, \quad c \in \mathbb{R}$, this
results in the integral
$$
\frac{1}{\sqrt{\pi}} \int_a^x \left(x-t\right)^{-\frac{1}{2}} c \di t
$$

This integral, when evaluated using the substitution $u=x-t$, results in the
function $\frac{c}{\sqrt{\pi x}}$. This contradicts normal intuition about
derivatives, that the derivative of a constant is $0$, which means that there
may be other intuitions we take about normal derivatives that do not hold for
fractional derivatives.

\subsubsection{Linearity}

The integer order derivative is said to be linear. That is, $\forall f(x),g(x),c \in \mathbb{R}$:
\begin{enumerate}
	\item{$\frac{d^n}{dx^n} \left(f + g\right) = \frac{d^n}{dx^n} f + \frac{d^n}{dx^n} g$}
	\item{$\frac{d^n}{dx^n} \left(cf\right) = c\frac{d^n}{dx^n} f$}
\end{enumerate}

This is one property that does hold for fractional derivatives as well. This
property is trivially proven, using the linearity of integrals and derivatives,
and the definition of the differintegral operator.

\subsubsection{Derivative rules}

For instance, using the same function above as an example, it may be proven by
contradiction that the product rule does not hold.

Proof: Let $f(x) = 1$ and $g(x) = 1$
\begin{gather*}
	D^\frac{1}{2} \left(f \cdot g\right) = D^\frac{1}{2} \left(1 \cdot 1\right) = D^\frac{1}{2} 1 = \frac{1}{\sqrt{\pi x}} \\
	g \cdot D^\frac{1}{2} f + f \cdot D^\frac{1}{2} g = 1 \cdot \frac{1}{\sqrt{\pi x}} + 1 \cdot \frac{1}{\sqrt{\pi x}} = \frac{2}{\sqrt{\pi x}} \neq \frac{1}{\sqrt{\pi x}}
\end{gather*}

This is also true for the quotient and chain rules, but these will not be
proven as the proofs are similar to the previous one. Moreover, there are also
no viable extensions of these rules to any type of fractional
derivative. However, there are general rules when it comes to specific
functions, such as $x^n$ and $\sin x$, which allow calculations of the
derivatives of those functions.

\subsubsection{Derivatives of specific functions} \label{der_examples}

This section presents derivatives of specific functions, in the case where the
parameter $a=0$. The reason for this is twofold: firstly, because the
relationships that are given are more complex and harder to derive with this
value, and secondly because the mapping between normal derivative and
fractional derivative relationships is made clearer. A more detailed
description of the effect of parameter $a$ is made in section
\ref{nonlocality}.

\textbf{Polynomial functions}

Polynomial functions are the most basic type of function, and the first one we
learnt to derive in our IB course. Therefore, we will discuss this type of
functions first. Despite the normal power rule not being valid for fractional
derivatives, as seen in the example presented above when taking the derivative
of $1$, there is an analogue to the power rule for fractional derivatives. This
rule is derived from a rule similar to the power rule that works for normal
derivatives, which states
$$
\frac{d^k}{dx^k} \left(x^n\right) = \frac{n!}{\left(n-k\right)!} x^{n-k}
$$
\parencite{ozaner2018}

This property is derived from the fact that you take the first $k$ terms of
$n!$.

This property is extendible to fractional derivatives and may be used when
calculating them. However, the proof that this works is outside the scope of
this exploration, as we are focusing mainly on the intuition behind fractional
derivatives, and how they relate to normal derivatives.

This formula also has factorials, just like Cauchy's formula, and therefore
when using it with fractional derivatives, we may use the exact same method we
used for Cauchy's formula. Therefore, the formula turns into
$$
D^\alpha \left(x^n\right) = \frac{\Gamma(n+1)}{\Gamma(n-\alpha + 1)} x^{n-\alpha}
$$

\textbf{Trigonometric functions}

Similarly, the identity for fractional derivatives of trigonometric functions
is derived from an identity used in normal derivatives. This identity is the
following
\begin{gather*}
\frac{d^n}{dx^n} \sin{x} = \sin\left(x + \frac{n\pi}{2}\right) \\
\frac{d^n}{dx^n} \cos{x} = \cos\left(x + \frac{n\pi}{2}\right)
\end{gather*}
\parencite{simplybeautifulart2016}

Naturally, this may also be extended to fractional calculus, although again
this will not be proven, as the proof of this fact requires complex
calculations.

Therefore, we have
\begin{gather*}
D^\alpha \left(\sin{x}\right) = \sin\left(x + \frac{\alpha\pi}{2}\right) \\
D^\alpha \left(\cos{x}\right) = \cos\left(x + \frac{\alpha\pi}{2}\right)
\end{gather*}

\textbf{Exponential functions}

Finally, the last ``common'' type of function that we encounter in our IB
course is the exponential function $e^x$. Just like the other functions, we
have a properety of normal derivatives that can be extended to the fractional
derivatives. This property is
$$
\frac{d^n}{dx^n} e^{kx} = k^ne^{kx}
$$
\parencite{dietrich2023}

Just like both previous types of functions, this property can be used for
fractional derivatives, even though we will not prove that this is the case.
When generalising this, we get the equation
$$
D^\alpha \left(e^{kx}\right) = k^\alpha e^{kx}
$$

Surprisingly, the idempotency of $e^x$ is maintained with fractional
derivatives. That is, if we take $D^\alpha e^x$, we see the following:
$$
D^\alpha e^x = 1^\alpha e^x = 1 e^x = e^x
$$
The derivative, of any degree, of $e^x$ is $e^x$, and this aligns with what we
see in normal derivatives. Therefore, this is one of the only things that are
maintained with fractional derivatives.

\subsection{Graphical interpretations of fractional derivatives}

\begin{figure}[H]
	\centering
	\includegraphics[width=\graphscale\textwidth]{graphs/polynomialquarterderivative.pdf}
	\caption{A graph of $\sin{x}$ and its $\frac{1}{4}$ order derivatives, up to order $1$} \label{polynomialfractionalgraph}
\end{figure}

In Figure \ref{xsquaredgraph}, we can see the graph of some fractional order
derivatives of $x^2$, approximated using technology. The picture shows how
these graphs fit between $x^2$ and its first order derivative, and moreover
how, as the order of the derivative increases, the graph gets closer to first
derivative. This is analogous to how the motivation for this investigation,
powers, work, as the graph of $x^\frac{3}{2}$ fits between $x^1$ and $x^2$,
which shows the parallels between these derivatives and normal exponents.

This is not only the case for polynomials, as this property is also true with
trigonometric functions as well.

\begin{figure}[H]
	\centering
	\includegraphics[width=\graphscale\textwidth]{graphs/sinquarterderivative.pdf}
	\caption{A graph of $\sin{x}$ and its $\frac{1}{4}$ order derivatives, up to order $1$} \label{sinfractionalgraph}
\end{figure}

These functions are being calculated using the identities discussed in section
\ref{der_examples}. Just like the polynomial case above, the fractional
derivative ``interpolates'' between the function and its derivative. Every
fractional derivative represents a state between the function and its
derivative, and eventually reaches the first order derivative.

\begin{figure}[H]
	\centering
	\includegraphics[width=\graphscale\textwidth]{graphs/exponentialquarterderivative.pdf}
	\caption{A graph of $e^{3x}$ and its $\frac{1}{4}$ order derivatives, up to order $1$} \label{exponentialfractionalgraph}
\end{figure}

One thing that may also be considered is the geometric meaning of the
fractional derivative, in terms of the original function. First order
derivatives show the slope at a point, and second order derivatives show the
concavity of the curve at any point. However, we struggle to find geometric
meaning in higher order derivatives, as the third derivative does not have a
commonly known geometric meaning. This is also the case for fractional order
derivatives, as according to \parencite{morphocular2022}, ``despite ordinary
derivatives and integrals having pretty straightforward geometric and physical
meanings, it seems no one has come up with a truly satisfying, general
interpretation of the fractional operators''

\subsection{Non-locality} \label{nonlocality}

An aspect of fractional derivatives that was thus far not considered in this
exploration is the value of $a$. Thus far, we have considered the value of
$a=0$, as it lent to neater formulas for fractional derivatives. However, now
we will consider what effect this value has on how derivatives are calculated.

At first glance, the value of $a$ may seem akin to the constant of integration,
$\int f(x) \di x = F(x) + C$, which is just a shift in the answer, that has no
bearing on the more complex behaviour of the function, like concavity or
slope. However, when looking at it further, the value of $a$ lends a more
complex property to fractional derivatives, which is non-locality.

Local operators are those that are affected by ``local'' behaviour of a
function, that is, behaviour in a surrounding neighbourhood of the point
considered. For instance, consider the following functions
$$
	f(x) =
	\begin{cases}
		2x, &\text{if } x < 0 \\

		x^2 + 3x + 5, &\text{if } x \geq 0 \\
	\end{cases}
$$
$$
	g(x) =
	\begin{cases}
		e^x, &\text{if } x < 0 \\

		x^2 + 3x + 5, &\text{if } x \geq 0 \\
	\end{cases}
$$
If we consider the value of $f'(x), \quad x \geq 0$, we may see the following graph:

\begin{figure}[H]
\centering
\includegraphics[width=\graphscale\textwidth]{graphs/derivativelocal.pdf}
\caption{A graph of $f'(x)$ and $g'(x)$} \label{firstderivativelocal}
\end{figure}

As seen in Figure \ref{firstderivativelocal}, despite the function being
defined differently before $0$, the value of the derivative is the same, as the
first derivative is, in fact, local.

However, when using the fractional derivative, specifically in this case the
half-derivative, we see a different behaviour.

\begin{figure}[H]
\def\figmax{10}
\centering
\begin{tikzpicture}[scale = 1.2]
    \begin{axis}[
		xmin = 0,
		xmax = \figmax,
		xlabel=$x$,
		ylabel=$y$,
		ylabel style = {rotate=-90},
		grid = both,
		major grid style = {lightgray},
		minor grid style = {lightgray!25},
		samples = 300,
		legend pos = north west,
	]
		\addplot[
			domain = 0:\figmax,
			smooth,
			thick,
			blue,
		] { 2*x+ 3 };

		\addplot[
			domain = 0:\figmax,
			smooth,
			thick,
			red,
			dotted,
		] { 2*x+ 3 };

	\addlegendentry{$f'(x)$}
	\addlegendentry{$g'(x)$}
    \end{axis}
\end{tikzpicture}
\caption{A graph of $D^\frac{1}{2} f(x)$ and $D^\frac{1}{2} g(x)$} \label{halfderivativenonlocal}
\end{figure}

\section{Conclusion}

\pagebreak

\addcontentsline{toc}{section}{References}
\printbibliography

\end{document}
