\documentclass{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage{titling}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{mathtools}
\usepackage{helvet}


\author{Guzm√°n Zugnoni}
\title{Non-integer order derivatives}

\renewcommand{\maketitle}{
\begin{center}
	\Huge\textbf \thetitle
\end{center}
}

\setlength{\parindent}{0pt}
%\setlength{\parskip}{20pt}
\doublespacing
\renewcommand{\familydefault}{\sfdefault}

\def\squad{\hskip2\fontdimen3\font}

\DeclareMathOperator{\di}{\,d\!}
\newcommand*\Eval[3]{\left[#1\right]_{#2}^{#3}}




\begin{document}
\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

My interest in this topic was born when we learned about the notion of second
and higher order derivatives. We learnt that there was a meaning and an
application of taking a derivative multiple times. The notation used to
represent this operation, however, made me relate it to something else.

To represent the second derivative for instance, one writes $\frac{d^2}{dx^2}$,
which encodes the fact that $\frac{d}{dx}$ was written twice by ``multiplying''
them and writing a $2$ in the exponent. This made me think about
exponentiation, which is the process of repeated multiplication, where
similarly $x \cdot x = x^2$. However, for exponentiation, we learn that it is
possible to exponentiate to non-integral, and non-positive powers, such as
$x^{-1}=\frac{1}{x}$ or $x^\frac{1}{2} = \sqrt{x}$, which have meaning and are
useful in solving mathematic problems, and this led me to think about if there
existed a similar notion regarding derivatives.

My focus in this exploration is going to be to find a way to generalise
higher-order derivatives to all $\mathbb{R}$, and not only $\mathbb{Z}^{+}$.

\section{Negative order derivative}

The most natural order to start defining non-integral derivatives is the same
order in which non-integer exponents are first learned,
firstly, exponentiating to negative integers. The expression
$\frac{d^{-1}}{dx^{-1}}$ has no obvious meaning, but it can be interpreted
alike exponents.

Firstly, throughout the exploration, I will use the notation
$$\frac{d^\alpha}{dx^\alpha}=D^\alpha \quad \forall \squad \alpha \in
\mathbb{R}$$
And for an arbitrary integrable function $f$:
$$\frac{d^\alpha}{dx^\alpha}\left(f\right) = D^\alpha f$$

By the definition of the second derivative, given an arbitrary differentiable
function $f$: $$D^1D^1 f = D^2 f$$ This can also be extended for the notion of
a third derivative: $$D^1D^2 f = D^3 f$$ It can be extrapolated that, more
generally,
\begin{equation}
	\label{der_sum}
	D^nD^m = D^{n+m} \quad \forall \squad n,m \in \mathbb{Z}^{+}
\end{equation}

This leads to defining negative order derivatives like negative order
exponents, where $x^1 \cdot x^{-1}= x^0$. Similarly, one might say that, by (\ref{der_sum})
\begin{equation}
	\label{inv_eq}
	D^1D^{-1} f = D^0 f
\end{equation}
and this leads to having to define what $D^0$ means.

It makes sense intuitively that taking the derivative of a function 0 times
would leave it without change, but I will check this verifies
algebraically. This is easy to do, as $$D^1 D^0 f = D^{1+0} f = D^1 f$$
Removing the $D^1$ from both sides gives the equation $$D^0 f = f$$ which
proves the intuition that this operation does nothing. This means that the 0th
power of the derivative operator is the identity operator.

Going back to (\ref{inv_eq}), we now see that
\begin{equation}
	\label{inv_eq_simplified}
	D^1D^{-1} f = f
\end{equation}
Since this is true for any arbitrary differentiable function $f$, and the order
of these two doesn't matter, i.e. $D^1D^{-1}=D^{-1}D^1$, we see these two
operators are inverses of each other, as composing them results in the
identity. Luckily, we know the inverse to the derivative operator, and that is
the integral. To find the value of $D^{-1}$, we can take the integral of both
sides of (\ref{inv_eq_simplified}), leading to the result
$$
D^{-1} f = \int f dx
$$

So far, negative order derivatives seem simple, as they match our intuition very cleanly:
0th derivatives do nothing, and negative derivatives do the opposite to a derivative.

This matches an initial guess one may have, which is that a negative derivative
would do the opposite of a positive derivative, but it is important to verify
and formalise this intuition to achieve more accurate results.

After learning about negative derivatives, one may see that they are hard to
evaluate, as a consequence of them involving integrals.

For instance, taking $f = \frac{8}{(x^2+1)^3}$:
$$
D^2\left(\frac{8}{(x^2+1)^3}\right) =
D\left(\frac{-48x}{(x^2+1)^4}\right) =
\frac{48x(7x^2-1)}{(x^2+1)^5}
$$

Despite there not being a general formula for the nth derivative of an
arbitrary function, one can easily arrive at the desired derivative by
performing repeated derivatives.

However, when trying to do the opposite, i.e. $D^{-2}$, the process is much
harder:

$$
D^{-2}\left(\frac{8}{(x^2+1)^3}\right) =
D^{-1}\left(\frac{x\left(3x^2+5\right)}{\left(x^2+1\right)^2} +
3\tan^{-1}{x} + C_1 \right)
$$

And performing the process of integration again will result in an even more
complicated result, with which performing repeated integration becomes
exponentially harder. Therefore, there is motivation to find a suitable
alternative to performing the integral every time, and a method to do this is
known as Cauchy's formula for repeated integration.

\section{Cauchy's formula for repeated integration}

The motivation for this formula is finding areas of threedimensional objects,
where integration may be performed twice to find the volume of an
object. However this formula may be used for the purposes of this investigation.

Cauchy's formula for repeated intregration is given thusly:
$$
\int_a^x
\int_a^{t_1}
\int_a^{t_2}
\ldots
\int_a^{t_{n-1}}f\left(t_n\right) dt_n \ldots dt_2 dt_1
=
\frac{1}{(n-1)!}\int_a^x\left(x-t\right)^{n-1}f\left(t\right)dt.
$$
where here $a$ is an arbitrary constant, alike the constant of integration.

This formula may be used to calculate the nth antiderivative for any function
easily. I will give a few examples of this method in use, calculating them both
by the normal method and Cauchy's Formula. For the sake of ease, I will assume
appropiate initial conditions such that all constant of integration will be
$0$.


\subsection{Proof for $n \in \mathbb{Z}$}

This may be proven for $n \in \mathbb{Z}^+$ by induction, for an arbitrary
integrable function $f$. The base is n=1, where it should simply be equal to
$\int
f\left(x\right)dx$:
$$
\frac{1}{(1-1)!}\int_a^x\left(x-t\right)^{1-1}f\left(t\right)dt =
\frac{1}{(0)!}\int_a^x\left(x-t\right)^{0}f\left(t\right)dt =
\int_a^xf\left(t\right)dt
$$

Thus, let $P_n$ be the proposition that Cauchy's formula holds for $n$. We may
assume that $P_k$ holds for some $k \in \mathbb{Z}^+$, and prove $P_{k+1}$
holds.

The formula for $n = k + 1$ would be:
$$
\int_a^x
\boxed{
\int_a^{t_1}
\int_a^{t_2}
\ldots
\int_a^{t_{k-1}}
\int_a^{t_k}f\left(t_{k+1}\right) \di t_{k+1}\di t_k\di t_{k-1} \ldots \di t_2}\di t_1
$$
The boxed region contains $k$ integrals, and thus, since $P_k$ holds, we may apply
Cauchy's formula to the integrals, which would result in the expression:
$$
\int_a^x
\frac{1}{(n-1)!}\int_a^{t_1}\left(t_1-t\right)^{n-1}f\left(t\right)\di t\di t_1
$$

Since when substituting $k+1$ in the formula the $x-t$ expression is raised to
the $k$th power, it is a good idea to achieve this. To do this, we must raise
the current power by 1, which may be achievable by writing it as a derivative,
like so:
$$
\int_a^x
\frac{1}{(n-1)!}\int_a^{t_1}\frac{\di}{\di t_1}\left[\frac{1}{n}\left(t_1-t\right)^nf\left(t\right)\right]\di t\di t_1
$$
This expression is very similar to the Fundamental Theorem of Calculus, which states:
\begin{equation}
	\label{fundamental_theorem_of_calculus}
\frac{\di}{\di x}\int_a^bf(x)\di x = \int_a^b\frac{\di}{\di x}f(x) \di x = f(b)- f(a)
\end{equation}
Applying (\ref{fundamental_theorem_of_calculus}) results in the expression becoming
\begin{gather*}
\int_a^x
\frac{1}{(n-1)!}\frac{\di}{\di t_1}\left[\int_a^{t_1}\frac{1}{n}\left(t_1-t\right)^nf(t)\di t\right]\di t_1 \\
\int_a^x
\frac{\di}{\di t_1}\left[\frac{1}{(n-1)!}\int_a^{t_1}\frac{1}{n}\left(t_1-t\right)^nf(t)\di t\right]\di t_1 \\
\int_a^x
\frac{\di}{\di t_1}\left[\frac{1}{(n-1)!}\frac{1}{n}\int_a^{t_1}\left(t_1-t\right)^nf(t)\di t\right]\di t_1 \\
\int_a^x
\frac{\di}{\di t_1}\left[\frac{1}{n!}\int_a^{t_1}\left(t_1-t\right)^nf(t)\di t\right]\di t_1
\end{gather*}
Applying(\ref{fundamental_theorem_of_calculus}) again eliminates the outer integral,
and results in
$$
\frac{1}{n!}\int_a^x\left(x-t\right)^nf(t)\di t -
\frac{1}{n!}\int_a^a\left(a-t\right)^nf(t)\di t =
\frac{1}{n!}\int_a^x\left(t_1-t\right)^nf(t)\di t
$$
which is $P_{k+1}$, and therefore by the principle of mathematical induction,
$$
\left(P_k \implies P_{k+1} \land P_1\right)
\implies P_n \forall n \in \mathbb{Z}^+
\qquad \blacksquare
$$

\subsection{Example}
As an example of how to use this formula, I will calculate a simple antiderivative,
that of $x^2$. Firstly, using the simple method of integration.
\begin{align*}
	&\iiiint x^2 \di x\di x\di x\di x \\
	&=\iiint \frac{x^3}{3} \di x\di x\di x \\
	&=\iint \frac{x^4}{12}\di x\di x \\
	&=\int \frac{x^5}{60} \di x \\
	&=\frac{x^6}{360}
\end{align*}
And secondly, using Cauchy's formula for integration:
\begin{gather*}
	\frac{1}{3!}\int_0^x \left(x-t\right)^3 t^2 \di t \\
	\frac{1}{6}\int_0^x \left(x^3 - 3x^2t + 3xt^2 - t^3\right)t^2 \di t \\
	\frac{1}{6}\int_0^x x^3t^2 - 3x^2t^3 + 3xt^4 - t^5 \di t \\
	\frac{1}{6} \Eval{\frac{x^3t^3}{3} - \frac{3x^2t^4}{4} + \frac{3xt^5}{5} - \frac{t^6}{6}}{0}{x} \\
	\frac{1}{6} \left(\frac{1}{3}x^6 - \frac{3}{4} x^6 + \frac{3}{5} x^6 - \frac{1}{6}x^6 \right) \\
	\frac{1}{6} \left(\frac{x^6}{60} \right) \\
	\frac{x^6}{360}
\end{gather*}

The results are the same and thus the formula seems to hold for a simple
function. However, one may realise that the second solution is in fact longer
and more complex than the traditional way of evaluating the integral. This is
much more evident, for instance in the example of $D^{-3} x^2$, where $\iiint
sin x \di x$ is rather easy to evaluate because of the simplicity and cyclical
nature of its antiderivatives, whereas $\frac{1}{2}\int \left(x-t\right)^2 \sin
t\di t$ involves much more work and complex techniques. This is a result of the
fact that integrals many times become much more difficult to evaluate when more
terms are introduced. Thus, despite the fact that this compresseses the work
needed to be done to one integral, the complexity is much greater.

This means that Cauchy's formula is in fact, not a practical way to calculate
negative order derivatives, even though it seems like it would be. Cauchy's
formula however has other uses cases, in places like applied mathematics for
calculating integrals numerically for instance, but most importantly for this
exploration, this formula can be generalised for non-integer integrals.

\subsection{Generalising Cauchy's integral formula for $x \in \mathbb{R}$}

\section{Fractional calculus}
\subsection{The differintegral operator}
\subsection{Properties of fractional derivatives}
\subsection{Graphical interpretations of fractional derivatives}
\subsubsection{Non-locality}

\end{document}
